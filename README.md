### 数据集来源

[商品分类-测试DEMO · 数据集](https://www.modelscope.cn/datasets/winwin_inc/product-classification-hiring-demo/files)

train.jsonl上传不上去，请自行去官网下载


这个文件是整个项目的核心，它实现了使用 BERT 模型对商品名称进行自动分类的完整训练流程。

1. **文件作用**：这个脚本的主要任务是从 `data/train.jsonl` 文件中读取训练数据，利用 Hugging Face 的 `transformers` 库加载预训练的 BERT 模型，然后在一个自定义的商品分类任务上进行微调（Fine-tuning）。训练完成后，会将表现最好的模型版本保存到 `model` 文件夹中，以便后续使用。

2. 关键组件 `BertProductTrainer` 类

   ：这个类封装了训练过程的所有细节。

   - **初始化**：在 `__init__` 方法里，它会首先加载预训练的 BERT 分词器（`BertTokenizer`）和模型结构（`BertForSequenceClassification`）。这里指定了 `num_classes`（类别数），告诉模型这是一个 N 分类任务。同时，它会将模型移动到 GPU 或 CPU 上（如果可用），并初始化一个 `LabelEncoder` 来处理类别标签（因为模型需要数字而非字符串标签）。
   - **数据加载与预处理**：`load_data` 方法负责读取 `.jsonl` 格式的数据。`prepare_data` 方法则提取出商品名称和对应的类别，并使用 `LabelEncoder` 将类别字符串转换成模型能理解的数字 ID。
   - **数据集 (`ProductDataset`)**：这是一个 PyTorch 的 `Dataset` 子类。它的作用是接收原始的文本和标签，然后利用 BERT 分词器将文本转换成 `input_ids` 和 `attention_mask` 这样的张量格式，这是 BERT 模型的标准输入。
   - **训练 (`train_epoch`) & 评估 (`evaluate`)**：这两个方法分别负责一个训练周期（epoch）的操作和模型评估。训练时会计算损失、进行反向传播更新模型参数；评估时则不更新参数，只是计算模型在验证集上的准确率和 F1 分数。
   - **主训练循环 (`train`)**：这是驱动整个训练过程的方法。它会循环指定的 `epochs` 次数，每次调用 `train_epoch` 训练，然后调用 `evaluate` 验证效果。它还会根据验证集的 F1 分数来判断是否保存当前的模型为“最佳模型”，防止过拟合。
   - **模型保存 (`save_model`)**：当训练结束或找到更好的模型时，这个方法会把模型的权重、分词器以及重要的 `LabelEncoder` 都保存起来，确保测试和部署时能正确加载。

3. **主函数 (`main`)**：程序的入口。它按顺序执行：创建训练器 -> 加载数据 -> 划分训练集和验证集 -> 开始训练 -> 保存最终模型。逻辑清晰，易于理解和运行。

4. **环境准备**：在脚本最下方，它会先检查所需的库 (`torch`, `transformers`, `joblib`) 是否已安装，如果没有则自动安装，保证代码能在大多数环境下顺利运行。

#### `test_model.py` 注释思路

这个文件用于检验我们训练好的模型效果如何，它会加载之前保存的模型，并在测试集上进行评估。

1. **文件作用**：该脚本旨在加载位于 `model` 文件夹中的已训练模型，并使用 `data/test.jsonl` 文件中的独立测试数据集来评估模型的真实性能。它会输出准确率、F1 分数等关键指标，并通过具体例子直观地展示模型的预测能力。

2. 核心类 `BertProductTester`

   ：

   - **模型加载 (`load_model`)**：`__init__` 方法会调用此方法，从 `model` 目录加载之前保存的模型、分词器和 `LabelEncoder`。这三者缺一不可，确保了模型能够以训练时的相同方式处理数据和解释输出。
   - **数据处理**：复用了与训练时相同的 `ProductDataset` 和 `create_data_loader`，保证了数据预处理流程的一致性。
   - **评估 (`evaluate`)**：与训练时的评估逻辑基本一致，但重点在于计算最终的测试集指标。
   - **预测功能 (`predict_single`, `predict_batch`)**：除了评估，这个类还提供了单条和批量预测的功能，方便在实际应用中进行推理。

3. **主函数 (`main`)**：执行完整的测试流程。加载测试数据 -> 使用加载的模型进行评估 -> 输出性能报告（如精确率、召回率、F1 分数的详细报告）-> 随机抽取几个测试样本，展示其“真实类别”和“模型预测类别”的对比，帮助我们直观感受模型的表现。

4. **环境准备**：同样包含了依赖库的自动安装检查。

#### `web_api.py` 注释思路

为了让训练好的模型能被其他应用方便地调用，我们把这个模型封装成了一个 Web 服务 API。

1. **文件作用**：此脚本利用轻量级的 Flask 框架，创建了一个 RESTful API 服务。外部应用可以通过发送 HTTP 请求（通常是 POST 请求）将待分类的商品名称发送给这个服务，API 会返回模型的预测结果。这使得模型可以作为一个独立的服务供他人调用。

2. 核心类 `BertProductAPI`

   ：

   - **初始化与加载**：与 `test_model.py` 类似，在 `__init__` 中加载已保存的模型、分词器和 `LabelEncoder`，并设置模型为评估模式（`eval()`），确保推理时行为正确。
   - **预测 (`predict_single`)**：这是 API 的核心推理逻辑，接收一段文本，执行分词、模型推理、解码等一系列操作，最终返回预测的类别和置信度。

3. API 路由 (Endpoints)

   ：

   - **`/predict` (POST)**：最基础的预测接口。客户端发送一个 JSON 包含 `"text"` 字段的请求，API 返回包含预测结果的 JSON。
   - **`/batch_predict` (POST)**：为了提高效率，提供了一个批量预测接口。客户端可以一次性发送一个包含多个文本的列表，API 会返回对应的结果列表。
   - **`/health` (GET)**：一个标准的健康检查接口，用于监控 API 服务是否处于可用状态。
   - **`/` (GET)**：一个简单的欢迎页，可以返回 API 的说明信息。

4. **服务启动**：脚本最后部分会启动 Flask Web 服务器，通常监听在 `localhost:5000`，这样外部就可以通过这个地址和端口访问我们的模型预测服务了。

---

多分类任务

conda终端中运行 web_api.py 与app_streamlit.py即可


环境：全部使用默认下载的
